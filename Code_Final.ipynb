{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ===============================================\n",
        "# üìö Dynamic EDA + Auto ML + XAI + PDF Generator\n",
        "# ===============================================\n",
        "\n",
        "# Install necessary packages\n",
        "#!pip install pandas numpy matplotlib seaborn scikit-learn shap lime fpdf2 plotly"
      ],
      "metadata": {
        "id": "1FJdCPvhPXQq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# üì¶ Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import shap\n",
        "import lime\n",
        "import lime.lime_tabular\n",
        "import joblib\n",
        "import datetime\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import accuracy_score, classification_report, mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from fpdf import FPDF\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "YwceFZCMPbZq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üì• Step 1: File Upload\n",
        "# ===============================\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Auto-detect file\n",
        "for fn in uploaded.keys():\n",
        "    dataset = pd.read_csv(fn)"
      ],
      "metadata": {
        "id": "0W-0HseaTw_i",
        "outputId": "4739c4b8-fe8c-4e1e-d93b-a5ffde70cafe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6f1a6d16-18a7-4378-a7fe-93f0f3d8896c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6f1a6d16-18a7-4378-a7fe-93f0f3d8896c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving StudentsPerformance.csv to StudentsPerformance (3).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìä Step 2: Dynamic EDA (Fixed)\n",
        "# ===============================\n",
        "\n",
        "# Detect numerical and categorical columns\n",
        "df = dataset.copy()\n",
        "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "categorical_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()\n",
        "\n",
        "# Create folders for images\n",
        "os.makedirs(\"eda_charts\", exist_ok=True)\n",
        "\n",
        "# Function to sanitize filenames\n",
        "def sanitize_filename(name):\n",
        "    return name.replace('/', '_').replace('\\\\', '_')\n",
        "\n",
        "# Descriptive Statistics\n",
        "descriptive_stats = df.describe(include='all')\n",
        "\n",
        "# Missing Values\n",
        "missing_values = df.isnull().sum()\n",
        "\n",
        "# Correlation Matrix\n",
        "correlation_matrix = df[numeric_cols].corr()\n",
        "\n",
        "# üìà Plot Numerical Distributions\n",
        "for col in numeric_cols:\n",
        "    safe_col = sanitize_filename(col)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.histplot(df[col], kde=True)\n",
        "    plt.title(f'Distribution of {col}')\n",
        "    plt.savefig(f\"eda_charts/{safe_col}_dist.png\")\n",
        "    plt.close()\n",
        "\n",
        "# üìà Boxplots and Violin Plots\n",
        "for col in numeric_cols:\n",
        "    safe_col = sanitize_filename(col)\n",
        "    fig, ax = plt.subplots(1, 2, figsize=(12,5))\n",
        "    sns.boxplot(y=df[col], ax=ax[0])\n",
        "    sns.violinplot(y=df[col], ax=ax[1])\n",
        "    ax[0].set_title(f'Boxplot of {col}')\n",
        "    ax[1].set_title(f'Violinplot of {col}')\n",
        "    plt.savefig(f\"eda_charts/{safe_col}_box_violin.png\")\n",
        "    plt.close()\n",
        "\n",
        "# üìà Categorical Countplots\n",
        "for col in categorical_cols:\n",
        "    safe_col = sanitize_filename(col)\n",
        "    plt.figure(figsize=(8,5))\n",
        "    sns.countplot(x=df[col])\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.title(f'Countplot of {col}')\n",
        "    plt.savefig(f\"eda_charts/{safe_col}_countplot.png\")\n",
        "    plt.close()\n",
        "\n",
        "# üìà Heatmap\n",
        "plt.figure(figsize=(12,8))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.savefig(\"eda_charts/correlation_heatmap.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "Z2SYD0vNT2TS"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üß† Step 3: Model Building (Fixed)\n",
        "# ===============================\n",
        "\n",
        "# Auto Problem Type Detection\n",
        "target = df.columns[-1]\n",
        "\n",
        "if df[target].dtype == 'object':\n",
        "    problem_type = 'classification'\n",
        "else:\n",
        "    problem_type = 'regression'\n",
        "\n",
        "# Prepare Data\n",
        "X = df.drop(columns=[target])\n",
        "y = df[target]\n",
        "\n",
        "# Encode Categorical Variables if any\n",
        "X_encoded = pd.get_dummies(X, drop_first=True)\n",
        "if y.dtype == 'object':\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Model\n",
        "if problem_type == 'classification':\n",
        "    model = RandomForestClassifier(random_state=42)\n",
        "else:\n",
        "    model = RandomForestRegressor(random_state=42)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Metrics\n",
        "if problem_type == 'classification':\n",
        "    model_score = accuracy_score(y_test, y_pred)\n",
        "    model_report = classification_report(y_test, y_pred)\n",
        "else:\n",
        "    model_score = r2_score(y_test, y_pred)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    model_rmse = np.sqrt(mse)\n",
        "\n",
        "# Save Model\n",
        "model_filename = f\"trained_model_{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}.pkl\"\n",
        "joblib.dump(model, model_filename)"
      ],
      "metadata": {
        "id": "oO18lgbQT3r6",
        "outputId": "1ca904be-79e2-42c2-8485-b0661a6afa5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['trained_model_20250428_165949.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üîç Step 4: Explainable AI (SHAP + LIME)\n",
        "# ===============================\n",
        "\n",
        "explainer = shap.TreeExplainer(model)\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# SHAP Summary\n",
        "plt.figure()\n",
        "shap.summary_plot(shap_values, X_test, show=False)\n",
        "plt.savefig(\"eda_charts/shap_summary.png\")\n",
        "plt.close()\n",
        "\n",
        "# SHAP Dependence (only first feature for demo)\n",
        "plt.figure()\n",
        "shap.dependence_plot(X_test.columns[0], shap_values, X_test, show=False)\n",
        "plt.savefig(\"eda_charts/shap_dependence.png\")\n",
        "plt.close()\n",
        "\n",
        "# LIME (Fixed)\n",
        "try:\n",
        "    if problem_type == 'classification':\n",
        "        lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, class_names=[str(i) for i in set(y_train)], discretize_continuous=True)\n",
        "        lime_exp = lime_explainer.explain_instance(X_test.iloc[0].values, model.predict_proba, num_features=5)\n",
        "    else:\n",
        "        lime_explainer = lime.lime_tabular.LimeTabularExplainer(X_train.values, feature_names=X_train.columns, discretize_continuous=True)\n",
        "        lime_exp = lime_explainer.explain_instance(X_test.iloc[0].values, model.predict, num_features=5)\n",
        "    lime_exp.save_to_file(\"eda_charts/lime_explanation.html\")\n",
        "except Exception as e:\n",
        "    print(f\"LIME explanation skipped due to error: {e}\")\n"
      ],
      "metadata": {
        "id": "mhXqjUF7T3dB",
        "outputId": "ecd344c1-e07c-4c1a-973c-b8f2b36d3daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LIME explanation skipped due to error: LIME does not currently support classifier models without probability scores. If this conflicts with your use case, please let us know: https://github.com/datascienceinc/lime/issues/16\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install python-docx"
      ],
      "metadata": {
        "id": "gajp4udeaogq",
        "outputId": "d47affb1-e21b-4611-aef9-9f0caf3a5418",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-docx\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[91m‚ï∏\u001b[0m\u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m71.7/244.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-docx\n",
            "Successfully installed python-docx-1.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===============================\n",
        "# üìÑ Step 5: Generate Professional Unicode-safe PDF/Word Report (Fixed Font + Safe Filenames)\n",
        "# ===============================\n",
        "\n",
        "!pip install python-docx\n",
        "\n",
        "import re\n",
        "from fpdf import FPDF, YPos\n",
        "from docx import Document\n",
        "from docx.shared import Pt\n",
        "import datetime\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# Helper function to sanitize filenames\n",
        "def sanitize_filename(name):\n",
        "    name = re.sub(r'[\\W_]+', '_', name)\n",
        "    return name.strip('_')\n",
        "\n",
        "class PDF(FPDF):\n",
        "    def header(self):\n",
        "        self.set_font('Helvetica', '', 24)\n",
        "        self.cell(0, 10, 'Automated ML Analysis Report', new_y=YPos.NEXT, align='C')\n",
        "        self.ln(5)\n",
        "\n",
        "    def chapter_title(self, title):\n",
        "        self.set_font('Helvetica', '', 18)\n",
        "        self.cell(0, 10, title, new_y=YPos.NEXT, align='L')\n",
        "        self.ln(3)\n",
        "\n",
        "    def chapter_body(self, body):\n",
        "        self.set_font('Helvetica', '', 12)\n",
        "        self.multi_cell(0, 10, body)\n",
        "        self.ln(5)\n",
        "\n",
        "    def add_image(self, path, w=180):\n",
        "        if os.path.exists(path):\n",
        "            self.image(path, w=w)\n",
        "            self.ln(5)\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "pdf = PDF()\n",
        "pdf.set_auto_page_break(auto=True, margin=15)\n",
        "\n",
        "# Cover Page\n",
        "pdf.add_page()\n",
        "pdf.set_font('Helvetica', '', 28)\n",
        "pdf.cell(0, 20, 'Dynamic Machine Learning Report', new_y=YPos.NEXT, align='C')\n",
        "pdf.ln(20)\n",
        "\n",
        "# Start Proper Report on Page 2\n",
        "pdf.add_page()\n",
        "\n",
        "# About Dataset\n",
        "pdf.chapter_title('About the Dataset')\n",
        "pdf.chapter_body(f\"The dataset contains {df.shape[0]} observations across {df.shape[1]} columns. Among them, {len(numeric_cols)} are numerical and {len(categorical_cols)} are categorical variables. A robust understanding of the data structure aids in selecting appropriate analysis and modeling techniques.\")\n",
        "\n",
        "# Exploratory Data Analysis\n",
        "pdf.chapter_title('Exploratory Data Analysis')\n",
        "for col in numeric_cols:\n",
        "    safe_col = sanitize_filename(col)\n",
        "    min_val = df[col].min()\n",
        "    max_val = df[col].max()\n",
        "    mean_val = df[col].mean()\n",
        "    std_val = df[col].std()\n",
        "    variability = 'low' if std_val < 0.1 * mean_val else 'moderate' if std_val < 0.5 * mean_val else 'high'\n",
        "    pdf.chapter_body(f\"The feature '{col}' ranges from {min_val:.2f} to {max_val:.2f}. The mean value is {mean_val:.2f} with a standard deviation of {std_val:.2f}, indicating {variability} variability. Visual analysis confirms that values cluster within this range, with few potential outliers influencing distribution tails.\")\n",
        "    pdf.add_image(f\"eda_charts/{safe_col}_dist.png\")\n",
        "    pdf.chapter_body(f\"Boxplots and violin plots of {col} reveal the central tendency around the median and help detect asymmetry and extreme values that may affect model assumptions.\")\n",
        "    pdf.add_image(f\"eda_charts/{safe_col}_box_violin.png\")\n",
        "\n",
        "for col in categorical_cols:\n",
        "    safe_col = sanitize_filename(col)\n",
        "    pdf.chapter_body(f\"The categorical feature '{col}' shows the frequency of each category. Understanding dominant or underrepresented classes is important for ensuring model fairness and effectiveness.\")\n",
        "    pdf.add_image(f\"eda_charts/{safe_col}_countplot.png\")\n",
        "\n",
        "pdf.chapter_body(\"The correlation heatmap visualizes relationships among numerical features. High correlations may indicate multicollinearity, which can bias model coefficients and reduce performance. Addressing these during preprocessing improves model robustness.\")\n",
        "pdf.add_image(\"eda_charts/correlation_heatmap.png\")\n",
        "\n",
        "# Model Building Section\n",
        "pdf.chapter_title('Model Building and Evaluation')\n",
        "pdf.chapter_body(f\"The task was identified as {problem_type.capitalize()}. A Random Forest model was used for its ability to capture non-linear relationships effectively without intensive preprocessing. The model achieved a performance score of {model_score:.4f}. {f'An RMSE of {model_rmse:.4f} indicates acceptable prediction accuracy for this domain.' if problem_type == 'regression' else ''}\")\n",
        "\n",
        "# XAI Section\n",
        "pdf.chapter_title('Explainable AI (XAI) Results')\n",
        "pdf.chapter_body(\"SHAP analysis identifies major feature influences globally, while dependence plots highlight feature interactions. LIME provides local, instance-based explanations enhancing model transparency.\")\n",
        "pdf.add_image(\"eda_charts/shap_summary.png\")\n",
        "pdf.add_image(\"eda_charts/shap_dependence.png\")\n",
        "\n",
        "# Conclusion Section\n",
        "pdf.chapter_title('Conclusion and Future Recommendations')\n",
        "pdf.chapter_body(\"This pipeline successfully automated dataset analysis, model building, evaluation, and interpretability. Future work can focus on model tuning, stacking methods like Gradient Boosting, and adding fairness and accountability checks for responsible AI deployment.\")\n",
        "\n",
        "# Save PDF\n",
        "pdf_filename = f\"ML_Report_{now.strftime('%Y-%m-%d_%H-%M-%S')}.pdf\"\n",
        "pdf.output(pdf_filename)\n",
        "print(f\"\\n‚úÖ PDF Report Generated: {pdf_filename}\")\n",
        "\n",
        "# Ask for Word Copy Option\n",
        "want_word = input(\"\\nDo you want a Word (.docx) copy too? (yes/no): \").strip().lower()\n",
        "if want_word == 'yes':\n",
        "    doc = Document()\n",
        "    doc.add_heading('Dynamic Machine Learning Report', 0)\n",
        "    doc.add_paragraph(f\"Automated ML Analysis Report\\nGenerated on: {now.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
        "\n",
        "    doc.add_heading('About the Dataset', level=1)\n",
        "    doc.add_paragraph(f\"{df.shape[0]} observations, {df.shape[1]} columns. Numerical Columns: {numeric_cols}. Categorical Columns: {categorical_cols}.\")\n",
        "\n",
        "    doc.add_heading('Exploratory Data Analysis', level=1)\n",
        "    for col in numeric_cols:\n",
        "        doc.add_paragraph(f\"Feature '{col}': Range {df[col].min():.2f} to {df[col].max():.2f}. Mean {df[col].mean():.2f}. Std {df[col].std():.2f}.\")\n",
        "    for col in categorical_cols:\n",
        "        doc.add_paragraph(f\"Feature '{col}': categorical distribution analyzed.\")\n",
        "\n",
        "    doc.add_heading('Model Building and Evaluation', level=1)\n",
        "    doc.add_paragraph(f\"Task: {problem_type.capitalize()}\\nModel: Random Forest\\nPerformance Score: {model_score:.4f}{f', RMSE: {model_rmse:.4f}' if problem_type == 'regression' else ''}\")\n",
        "\n",
        "    doc.add_heading('Explainable AI Results', level=1)\n",
        "    doc.add_paragraph(\"SHAP and LIME analyses provided critical global and local model explanations.\")\n",
        "\n",
        "    doc.add_heading('Conclusion and Future Recommendations', level=1)\n",
        "    doc.add_paragraph(\"Future improvements include hyperparameter optimization and fairness evaluations.\")\n",
        "\n",
        "    word_filename = f\"ML_Report_{now.strftime('%Y-%m-%d_%H-%M-%S')}.docx\"\n",
        "    doc.save(word_filename)\n",
        "    files.download(word_filename)\n",
        "    print(f\"‚úÖ Word Report Generated: {word_filename}\")\n",
        "\n",
        "# Download the generated PDF file\n",
        "files.download(pdf_filename)\n"
      ],
      "metadata": {
        "id": "DxdOr3tQV1fi",
        "outputId": "d7df86d4-dcfa-450e-fb5b-1e6e8f5d3008",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-docx in /usr/local/lib/python3.11/dist-packages (1.1.2)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (5.3.2)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.11/dist-packages (from python-docx) (4.13.2)\n",
            "\n",
            "‚úÖ PDF Report Generated: ML_Report_2025-04-28_17-53-21.pdf\n",
            "\n",
            "Do you want a Word (.docx) copy too? (yes/no): no\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_97a8dda0-3813-40b3-b3bb-a661c00796b4\", \"ML_Report_2025-04-28_17-53-21.pdf\", 192889)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}